#ifndef _MATRIXOPERATIONS_CUT_
#define _MATRIXOPERATIONS_CUT_

template <>
template <typename UnaryOperation>
void MatrixOperations<HostMatrix>::transform(HostMatrix& matrix, UnaryOperation op) {
    for (unsigned int i = 0; i < matrix.getHeight(); ++i) {
        for (unsigned int j = 0; j < matrix.getWidth(); ++j) {
            matrix.setElement(i, j, op(matrix.getElement(i, j)));
        }
    }
}

template <typename UnaryOperation>
__global__
void _transform(float* matrix, unsigned int m, unsigned int n, UnaryOperation op) {
    unsigned int global_i = threadIdx.y + blockIdx.y * blockDim.y;
    unsigned int global_j = threadIdx.x + blockIdx.x * blockDim.x;

    if (global_i < m && global_j < n) {
        matrix[global_i * n + global_j] = op(matrix[global_i * n + global_j]);
    }
}

template <>
template <typename UnaryOperation>
void MatrixOperations<DeviceMatrix>::transform(DeviceMatrix& matrix, UnaryOperation op) {
    dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);
    dim3 gridDim((matrix.getWidth() + BLOCK_SIZE - 1) / BLOCK_SIZE,
        (matrix.getHeight() + BLOCK_SIZE - 1) / BLOCK_SIZE);
    _transform<<<gridDim, blockDim>>>(matrix.getElements(), matrix.getHeight(), matrix.getWidth(), op);
}

template <typename MatrixType>
void MatrixOperations<MatrixType>::fill(MatrixType& matrix, float value) {
    transform(matrix, Fill(value));
}

template <typename MatrixType>
void MatrixOperations<MatrixType>::negate(MatrixType& matrix) {
    transform(matrix, Negate());
}

template <>
template <typename BinaryOperation>
HostMatrix MatrixOperations<HostMatrix>::combineElementWise(
    const HostMatrix& matrixA, const HostMatrix& matrixB, BinaryOperation op) {
    if (matrixA.getHeight() != matrixB.getHeight() || matrixA.getWidth() != matrixB.getWidth()) {
        throw std::invalid_argument("Invalid argument.");
    } else {
        HostMatrix matrixC(matrixA.getHeight(), matrixA.getWidth());
        for (unsigned int i = 0; i < matrixC.getHeight(); ++i) {
            for (unsigned int j = 0; j < matrixC.getWidth(); ++j) {
                matrixC.setElement(i, j, op(matrixA.getElement(i, j), matrixB.getElement(i, j)));
            }
        }
        return matrixC;
    }
}

template <typename BinaryOperation>
__global__
void _combineElementWise(const float* matrix_a, const float* matrix_b, float* matrix_c,
    unsigned int m, unsigned int n, BinaryOperation op) {
    unsigned int global_i = threadIdx.y + blockIdx.y * blockDim.y;
    unsigned int global_j = threadIdx.x + blockIdx.x * blockDim.x;

    if (global_i < m && global_j < n) {
        matrix_c[global_i * n + global_j] =
            op(matrix_a[global_i * n + global_j], matrix_b[global_i * n + global_j]);
    }
}

template <>
template <typename BinaryOperation>
DeviceMatrix MatrixOperations<DeviceMatrix>::combineElementWise(
    const DeviceMatrix& matrixA, const DeviceMatrix& matrixB, BinaryOperation op) {
    if (matrixA.getHeight() != matrixB.getHeight() || matrixA.getWidth() != matrixB.getWidth()) {
        throw std::invalid_argument("Invalid argument.");
    } else {
        DeviceMatrix matrixC(matrixA.getHeight(), matrixA.getWidth());
        dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);
        dim3 gridDim((matrixC.getWidth() + BLOCK_SIZE - 1) / BLOCK_SIZE,
            (matrixC.getHeight() + BLOCK_SIZE - 1) / BLOCK_SIZE);
        _combineElementWise<<<gridDim, blockDim>>>(matrixA.getElements(), matrixB.getElements(),
            matrixC.getElements(), matrixC.getHeight(), matrixC.getWidth(), op);
        return matrixC;
    }
}

template <typename MatrixType>
MatrixType MatrixOperations<MatrixType>::add(const MatrixType& matrixA, const MatrixType& matrixB) {
    return combineElementWise(matrixA, matrixB, Add());
}

template <typename MatrixType>
MatrixType MatrixOperations<MatrixType>::subtract(const MatrixType& matrixA, const MatrixType& matrixB) {
    return combineElementWise(matrixA, matrixB, Subtract());
}

template <typename MatrixType>
MatrixType MatrixOperations<MatrixType>::divide(const MatrixType& matrixA, const MatrixType& matrixB) {
    return combineElementWise(matrixA, matrixB, Divide());
}

template <>
template <typename BinaryOperation1, typename BinaryOperation2, typename UnaryOperation>
HostMatrix MatrixOperations<HostMatrix>::combineInnerProduct(
    const HostMatrix& matrixA, const HostMatrix& matrixB,
    BinaryOperation1 opA, BinaryOperation2 opB, UnaryOperation opC, float identity) {
    if (matrixA.getWidth() != matrixB.getHeight()) {
        throw std::invalid_argument("Invalid argument.");
    } else {
        HostMatrix matrixC(matrixA.getHeight(), matrixB.getWidth());
        for (unsigned int i = 0; i < matrixC.getHeight(); ++i) {
            for (unsigned int j = 0; j < matrixC.getWidth(); ++j) {
                float value = identity;
                for (unsigned int k = 0; k < matrixA.getWidth(); ++k) {
                    value = opB(value, opA(matrixA.getElement(i, k), matrixB.getElement(k, j)));
                }
                matrixC.setElement(i, j, opC(value));
            }
        }
        return matrixC;
    }
}

template <typename BinaryOperation1, typename BinaryOperation2, typename UnaryOperation>
__global__
void _combineInnerProduct(const float* matrix_a, const float* matrix_b, float* matrix_c,
    unsigned int m, unsigned int p, unsigned int n,
    BinaryOperation1 op_a, BinaryOperation2 op_b, UnaryOperation op_c, float identity) {
    __shared__ extern float shared_mem_cip[];
    float* s_a = shared_mem_cip;
    float* s_b = shared_mem_cip + blockDim.x * blockDim.y;

    unsigned int local_i = threadIdx.y;
    unsigned int local_j = threadIdx.x;
    unsigned int global_i = 0;
    unsigned int global_j = 0;

    unsigned int offset_i_a = blockIdx.y * blockDim.y;
    unsigned int offset_j_a = 0;
    unsigned int step_j_a = blockDim.x;
    unsigned int offset_i_b = 0;
    unsigned int offset_j_b = blockIdx.x * blockDim.x;
    unsigned int step_i_b = blockDim.y;

    unsigned int loop = (p + blockDim.x - 1) / blockDim.x;
    float value = identity;
    for (unsigned int l = 0; l < loop; ++l, offset_j_a += step_j_a, offset_i_b += step_i_b) {
        global_i = offset_i_a + local_i;
        global_j = offset_j_a + local_j;
        s_a[local_i * blockDim.x + local_j] = (global_i < m && global_j < p)?
            matrix_a[global_i * p + global_j]: identity;
        global_i = offset_i_b + local_i;
        global_j = offset_j_b + local_j;
        s_b[local_i * blockDim.x + local_j] = (global_i < p && global_j < n)?
            matrix_b[global_i * n + global_j]: identity;
        __syncthreads();

        for (unsigned int k = 0; k < blockDim.x; ++k) {
            value = op_b(value, op_a(s_a[local_i * blockDim.x + k], s_b[k * blockDim.x + local_j]));
        }
        __syncthreads();
    }

    global_i = threadIdx.y + blockIdx.y * blockDim.y;
    global_j = threadIdx.x + blockIdx.x * blockDim.x;
    if (global_i < m && global_j < n) {
        matrix_c[global_i * n + global_j] = op_c(value);
    }
}

template <>
template <typename BinaryOperation1, typename BinaryOperation2, typename UnaryOperation>
DeviceMatrix MatrixOperations<DeviceMatrix>::combineInnerProduct(
    const DeviceMatrix& matrixA, const DeviceMatrix& matrixB,
    BinaryOperation1 opA, BinaryOperation2 opB, UnaryOperation opC, float identity) {
    if (matrixA.getWidth() != matrixB.getHeight()) {
        throw std::invalid_argument("Invalid argument.");
    } else {
        DeviceMatrix matrixC(matrixA.getHeight(), matrixB.getWidth());
        dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);
        dim3 gridDim((matrixC.getWidth() + BLOCK_SIZE - 1) / BLOCK_SIZE,
            (matrixC.getHeight() + BLOCK_SIZE - 1) / BLOCK_SIZE);
        unsigned int sharedMem = BLOCK_SIZE * BLOCK_SIZE * sizeof(float) * 2;
        _combineInnerProduct<<<gridDim, blockDim, sharedMem>>>(
            matrixA.getElements(), matrixB.getElements(), matrixC.getElements(),
            matrixC.getHeight(), matrixA.getWidth(), matrixC.getWidth(),
            opA, opB, opC, identity);
        return matrixC;
    }
}

template <typename MatrixType>
MatrixType MatrixOperations<MatrixType>::multiply(const MatrixType& matrixA, const MatrixType& matrixB) {
    return combineInnerProduct(matrixA, matrixB, Multiply(), Add(), Identity(), 0.0f);
}

template <>
template <typename BinaryOperation, typename UnaryOperation>
HostMatrix MatrixOperations<HostMatrix>::reduceColumns(const HostMatrix& matrix,
    BinaryOperation opA, UnaryOperation opB, float identity) {
    HostMatrix vector(1, matrix.getWidth());
    for (unsigned int j = 0; j < matrix.getWidth(); ++j) {
        float value = identity;
        for (unsigned int i = 0; i < matrix.getHeight(); ++i) {
            value = opA(value, matrix.getElement(i, j));
        }
        vector.setElement(0, j, opB(value));
    }
    return vector;
}

template <typename BinaryOperation, typename UnaryOperation>
__global__
void _reduceColumns(const float* matrix, float* vector, unsigned int m, unsigned int n,
    BinaryOperation op_a, UnaryOperation op_b, float identity) {
    __shared__ extern float shared_mem_rc[];
    float* s = shared_mem_rc;

    unsigned int local_i = threadIdx.y;
    unsigned int local_j = threadIdx.x;
    unsigned int global_j = threadIdx.x + blockIdx.x * blockDim.x;
    unsigned int offset_i = 0;
    unsigned int step_i = blockDim.y;

    s[local_i * blockDim.x + local_j] = identity;
    while (offset_i < m) {
        s[local_i * blockDim.x + local_j] = op_a(s[local_i * blockDim.x + local_j],
            (local_i + offset_i < m && global_j < n)?
            matrix[(local_i + offset_i) * n + global_j]: identity);
        offset_i += step_i;
    }

    for (step_i >>= 1; step_i > 0; step_i >>= 1) {
        __syncthreads();
        if (local_i < step_i) {
            s[local_i * blockDim.x + local_j] = op_a(s[local_i * blockDim.x + local_j],
                s[(local_i + step_i) * blockDim.x + local_j]);
        }
    }

    if (local_i == 0 && global_j < n) {
        vector[global_j] = op_b(s[local_j]);
    }
}

template <>
template <typename BinaryOperation, typename UnaryOperation>
DeviceMatrix MatrixOperations<DeviceMatrix>::reduceColumns(const DeviceMatrix& matrix,
    BinaryOperation opA, UnaryOperation opB, float identity) {
    DeviceMatrix vector(1, matrix.getWidth());
    dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);
    dim3 gridDim((matrix.getWidth() + BLOCK_SIZE - 1) / BLOCK_SIZE, 1);
    unsigned int sharedMem = BLOCK_SIZE * BLOCK_SIZE * sizeof(float);
    _reduceColumns<<<gridDim, blockDim, sharedMem>>>(matrix.getElements(), vector.getElements(),
        matrix.getHeight(), matrix.getWidth(), opA, opB, identity);
    return vector;
}

template <typename MatrixType>
MatrixType MatrixOperations<MatrixType>::sumColumns(const MatrixType& matrix) {
    return reduceColumns(matrix, Add(), Identity(), 0.0f);
}

template <>
template <typename BinaryIndexedOperation>
HostMatrix MatrixOperations<HostMatrix>::reduceColumnsIndexed(const HostMatrix& matrix,
    BinaryIndexedOperation op, IndexedValue identity) {
    HostMatrix vector(1, matrix.getWidth());
    for (unsigned int j = 0; j < matrix.getWidth(); ++j) {
        IndexedValue value = identity;
        for (unsigned int i = 0; i < matrix.getHeight(); ++i) {
            value = op(value, IndexedValue(matrix.getElement(i, j), i));
        }
        vector.setElement(0, j, (float)value.index);
    }
    return vector;
}

template <typename BinaryIndexedOperation>
__global__
void _reduceColumnsIndexed(const float* matrix, float* vector, unsigned int m, unsigned int n,
    BinaryIndexedOperation op, IndexedValue identity) {
    __shared__ extern IndexedValue shared_mem_rci[];
    IndexedValue* s = shared_mem_rci;

    unsigned int local_i = threadIdx.y;
    unsigned int local_j = threadIdx.x;
    unsigned int global_j = threadIdx.x + blockIdx.x * blockDim.x;
    unsigned int offset_i = 0;
    unsigned int step_i = blockDim.y;

    s[local_i * blockDim.x + local_j] = identity;
    while (offset_i < m) {
        s[local_i * blockDim.x + local_j] = op(s[local_i * blockDim.x + local_j],
            (local_i + offset_i < m && global_j < n)?
            IndexedValue(matrix[(local_i + offset_i) * n + global_j], local_i + offset_i): identity);
        offset_i += step_i;
    }

    for (step_i >>= 1; step_i > 0; step_i >>= 1) {
        __syncthreads();
        if (local_i < step_i) {
            s[local_i * blockDim.x + local_j] = op(s[local_i * blockDim.x + local_j],
                s[(local_i + step_i) * blockDim.x + local_j]);
        }
    }

    if (local_i == 0 && global_j < n) {
        vector[global_j] = (float)s[local_j].index;
    }
}

template <>
template <typename BinaryIndexedOperation>
DeviceMatrix MatrixOperations<DeviceMatrix>::reduceColumnsIndexed(const DeviceMatrix& matrix,
    BinaryIndexedOperation op, IndexedValue identity) {
    DeviceMatrix vector(1, matrix.getWidth());
    dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);
    dim3 gridDim((matrix.getWidth() + BLOCK_SIZE - 1) / BLOCK_SIZE, 1);
    unsigned int sharedMem = BLOCK_SIZE * BLOCK_SIZE * sizeof(IndexedValue);
    _reduceColumnsIndexed<<<gridDim, blockDim, sharedMem>>>(matrix.getElements(), vector.getElements(),
        matrix.getHeight(), matrix.getWidth(), op, identity);
    return vector;
}

template <typename MatrixType>
MatrixType MatrixOperations<MatrixType>::minColumnsIndexed(const MatrixType& matrix) {
    return reduceColumnsIndexed(matrix, MinIndexed(),
        IndexedValue(std::numeric_limits<float>::max(), std::numeric_limits<unsigned int>::max()));
}

template <>
template <typename BinaryOperation1, typename UnaryOperation, typename BinaryOperation2>
void MatrixOperations<HostMatrix>::reduceTransformColumns(HostMatrix& matrix,
    BinaryOperation1 opA, UnaryOperation opB, BinaryOperation2 opC, float identity) {
    for (unsigned int j = 0; j < matrix.getWidth(); ++j) {
        float value = identity;
        for (unsigned int i = 0; i < matrix.getHeight(); ++i) {
            value = opA(value, matrix.getElement(i, j));
        }
        value = opB(value);
        for (unsigned int i = 0; i < matrix.getHeight(); ++i) {
            matrix.setElement(i, j, opC(matrix.getElement(i, j), value));
        }
    }
}

template <typename BinaryOperation1, typename UnaryOperation, typename BinaryOperation2>
__global__
void _reduceTransformColumns(float* matrix, unsigned int m, unsigned int n,
    BinaryOperation1 op_a, UnaryOperation op_b, BinaryOperation2 op_c, float identity) {
    __shared__ extern float shared_mem_rtc[];
    float* s = shared_mem_rtc;

    unsigned int local_i = threadIdx.y;
    unsigned int local_j = threadIdx.x;
    unsigned int global_j = threadIdx.x + blockIdx.x * blockDim.x;
    unsigned int offset_i = 0;
    unsigned int step_i = blockDim.y;

    s[local_i * blockDim.x + local_j] = identity;
    while (offset_i < m) {
        s[local_i * blockDim.x + local_j] = op_a(s[local_i * blockDim.x + local_j],
            (local_i + offset_i < m && global_j < n)?
            matrix[(local_i + offset_i) * n + global_j]: identity);
        offset_i += step_i;
    }

    for (step_i >>= 1; step_i > 0; step_i >>= 1) {
        __syncthreads();
        if (local_i < step_i) {
            s[local_i * blockDim.x + local_j] = op_a(s[local_i * blockDim.x + local_j],
                s[(local_i + step_i) * blockDim.x + local_j]);
        }
    }

    if (local_i == 0) {
        s[local_j] = op_b(s[local_j]);
    }
    __syncthreads();

    offset_i = 0;
    step_i = blockDim.y;
    while (offset_i < m) {
        if (local_i + offset_i < m && global_j < n) {
            matrix[(local_i + offset_i) * n + global_j] =
                op_c(matrix[(local_i + offset_i) * n + global_j], s[local_j]);
        }
        offset_i += step_i;
    }
}

template <>
template <typename BinaryOperation1, typename UnaryOperation, typename BinaryOperation2>
void MatrixOperations<DeviceMatrix>::reduceTransformColumns(DeviceMatrix& matrix,
    BinaryOperation1 opA, UnaryOperation opB, BinaryOperation2 opC, float identity) {
    dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);
    dim3 gridDim((matrix.getWidth() + BLOCK_SIZE - 1) / BLOCK_SIZE, 1);
    unsigned int sharedMem = BLOCK_SIZE * BLOCK_SIZE * sizeof(float);
    _reduceTransformColumns<<<gridDim, blockDim, sharedMem>>>(matrix.getElements(),
        matrix.getHeight(), matrix.getWidth(), opA, opB, opC, identity);
}

template <typename MatrixType>
void MatrixOperations<MatrixType>::normalizeColumns(MatrixType& matrix) {
    reduceTransformColumns(matrix, Add(), DivideBy((float)matrix.getHeight()), Subtract(), 0.0f);
}

#endif